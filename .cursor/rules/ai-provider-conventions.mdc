---
description: Conventions for implementing and maintaining AI providers (AnthropicProvider, OpenAIProvider) in the frontend SDK
globs: packages/frontend/src/sdk/providers/**/*
alwaysApply: false
---

# AI Provider Implementation Conventions

This rule documents the conventions, patterns, and guardrails for implementing and maintaining AI providers. It is based on the current implementations of `AnthropicProvider` and `OpenAIProvider` and applies to files under `packages/frontend/src/sdk/providers/`.

Follow these guidelines when editing existing providers or adding new ones.

## Provider Class Structure

Every provider must extend the abstract `API` base and implement its required hooks using provider-specific types:

- **Class signature**: `export class <ProviderName>Provider extends API<ProviderSession, ProviderToolSchema>`
- **Required members**:
  - `protected readonly API_BASE_URL: string`
  - `constructor(apiKey: string)` that calls `this.setApiKey(apiKey)`
  - `protected buildAPIRequest(method: RequestInit["method"])`
  - `protected ensureSuccess(response: Response)`
  - `protected translateSession(session: SessionTurns)`
  - `protected translateToolSchema(schema: IToolMetaJson[])`
  - `async getModels(): Promise<IModelInfo[]>`
  - `getDefaultModelConfig(modelId: string)`
  - `protected getModelConfig(modelId: string)`
  - `getModelConfigSchema(modelId: string)`
  - `async message(session, model, result, setStop, tools, signal?)`

Notes:

- Always use `proxyfetch` for network calls and pass the `AbortSignal` when available.
- Always call `await this.ensureSuccess(response)` immediately after the request to normalize provider-side errors.
- Never write to storage from a provider. Persisting session state is centralised in `AISDK`.

## Model Registry and Info

Each provider maintains a local in-memory registry with model metadata.

- Define `const <Provider>ModelRegistry = [{ id, displayName, ... }]`.
- Expose `getModels()` returning `IModelInfo[]` with fields `{ provider, id, displayName, disabled }` (disabled is typically `false`).
- Provide `getModelInfo(modelId: string)` that looks up the registry.
- Use registry values to power validation boundaries in config schemas (e.g. `maxOutput`).

Anthropic-only fields present today (optional for UI but keep accurate):

- `extendedThinking`, `contextWindow`, `maxOutput`, `pricing` with `baseInput`, `output`, and cache fields.

OpenAI-only fields present today:

- `reasoning` capability and `streaming` flag.

## API Key and Headers

- Set API key exclusively via `this.setApiKey(apiKey)` in the constructor; do not store credentials elsewhere.
- `buildAPIRequest` must construct headers exactly as required by the provider:
  - Anthropic: `x-api-key`, `anthropic-version`, `content-type`.
  - OpenAI: `Authorization: Bearer <key>`, `content-type`.
- Return shape must be `{ headers, method }` plus an optional `body` object (call site will JSON-encode).

## Error Handling

- Implement `ensureSuccess` to normalize provider-specific error formats into `ExpectedError` when possible; otherwise raise `ServerSideHttpError`.
- During streaming, handle provider-specific streaming errors embedded in SSE frames and raise `ExpectedError` with a provider prefix in the message.
- Provide an `UnexpectedMessageTypeError` class for logging/debugging if an unknown event surfaces.

Good:

```typescript
// After fetch
await this.ensureSuccess(response);
```

Bad:

```typescript
// Skipping success checks – causes silent failures later
// await this.ensureSuccess(response);
```

## Session Translation

Translate our canonical `SessionTurns` into provider-native request payloads.

- Skip provider-internal/tool orchestration turns: `if (turn.type === "tool") continue;`
- Map request turns to the provider’s user/developer/system messages.
- Map response turns only when needed by the provider (e.g., OpenAI needs IDs on content for continuity).
- Ignore or elide unsupported content types (e.g., thinking blocks for providers that don’t accept them in input).

Provider specifics:

- Anthropic request payload `messages` contains content blocks (`text`, `tool_use`, `tool_result`). Thinking is ignored in input.
- OpenAI request payload uses the Responses API input types:
  - Requests: `message` with `input_text` parts
  - Tool results: `function_call_output`
  - Response mapping uses provider-assigned item IDs (`openai_id`) to stitch streams back to the right result entries.

## System Prompts Convention

- Always include the current datetime as a first system prompt.
- Merge user-defined prompts from `localStorage[SYSTEM_PROMPTS_KEY]` if present.
- Anthropic: pass as `system: [{ type: "text", text: ... }, ...]`.
- OpenAI: splice a `system` message at the start of the `messages` input with `input_text` parts.

Good:

```typescript
const systemPrompts = [
  { type: "text", text: "Today's datetime is " + new Date().toISOString() },
];
// append validated user prompts...
```

## Tool Schema Translation

Translate `IToolMetaJson` to provider-specific tool schemas.

- Anthropic: `{ name, description, input_schema }`.
- OpenAI: `{ type: "function", name, parameters, description, strict: false }`.
- The `name` must match the tool `id` and be stable; arguments are streamed as JSON deltas.

## Message() Responsibilities

The `message()` method is the streaming workhorse and must:

1. Translate the session and model config
2. Prepare system prompts (see above)
3. Send the request with `proxyfetch` and `signal`
4. `await this.ensureSuccess(response)`
5. Stream-parse SSE lines (`data: ...`) and update `result()` with `IMessageResult[]` entries
6. Map provider stop reasons to `setStop(...)`
7. Release the reader lock in a `finally` block

### Streaming Conventions

- Always read the response body as a stream and process newline-delimited SSE events that begin with `data: `.
- Maintain stable indices/maps to reconcile partial updates:
  - Anthropic: `contentBlockMap: Record<number, number>` maps provider content index → result array index.
  - OpenAI: `itemIdToTextIndex`, `itemIdToRefusalIndex`, `itemIdToToolIndex`, `toolCallIndexByCallId`, `reasoningIndexById`.
- Emit lifecycle markers:
  - Push `{ type: "start" }` when the assistant turn begins
  - Push `{ type: "end" }` when the turn is completed or terminal

### Stop Reason Mapping

- Map provider stop reasons to one of:
  - `{ type: "log", message }` for informational completion
  - `{ type: "message", reason, level }` for user-visible messages
  - `{ type: "tool_use" }` when tool calls are ready

Examples:

- Anthropic `stop_reason` values: `end_turn`, `max_tokens`, `stop_sequence`, `tool_use`, `pause_turn`, `refusal` → mapped accordingly.
- OpenAI responses events: `response.completed`, `response.failed`, `response.incomplete`, `response.function_call_arguments.done` → mapped accordingly.

### Tool Use Streaming

- Stream function/tool arguments as deltas and accumulate into the corresponding `IMessageResultToolUse.input`.
- When finalised, set stop to `{ type: "tool_use" }` so `AISDK` can enqueue tool execution.

## Model Configuration

Each provider owns its model config schema and persistence boundary.

- `getDefaultModelConfig(modelId)` must derive sane defaults from the model registry (e.g., `maxOutput` upper bounds and feature flags like `reasoning` or `extendedThinking`).
- `getModelConfig(modelId)` must attempt to parse `localStorage[PER_MODEL_CONFIG_KEY(providerId, modelId)]` and merge over defaults; on parse errors, log and fall back to defaults.
- `getModelConfigSchema(modelId)` returns a tuple:
  1. UI schema map: `Record<keyof Config, IConfigSchema>`
  2. Validation schema: `z.ZodSchema<Config>`

Disable/enable logic must match capabilities:

- OpenAI: disable `temperature` when `reasoning` is enabled; `reasoningEffort` disabled when `reasoning` is false.
- Anthropic: disable `temperature` when `extendedThinking` is enabled; `thinkingBudget` disabled unless `extendedThinking` is enabled and must be `< maxOutput`.

Good:

```typescript
return [
  {
    temperature: {
      type: "number",
      min: 0,
      max: 2,
      step: 0.1,
      disabled: { $ref: "reasoning" },
    },
    // ...
  },
  z.object({
    /* mirrors UI constraints */
  }),
];
```

## Networking

- Always use `proxyfetch(this.API_BASE_URL + endpoint, { ...this.buildAPIRequest("POST"), body, signal })`.
- JSON bodies are provided as plain objects; do not `JSON.stringify` manually.
- Do not use fetch directly; keep provider calls behind the proxy to unify error handling and CORS.

## Performance and Clean-up

- Providers must not write to storage or manage throttling. They only call the provided `result(updator)` to mutate the in-memory result message array.
- Always `releaseLock()` on the reader in a `finally` block to avoid leaked streams.

## Adding or Updating Models

When adding/updating a model entry in the registry:

- Keep `id` exact as the provider expects.
- Provide `displayName` in title case.
- Update feature flags (`reasoning`, `extendedThinking`) and bounds (`maxOutput`).
- For Anthropic, keep pricing fields accurate if known (used for display and potential cost computations later).
- Update `getDefaultModelConfig` bounds (`maxOutput`, etc.) to reflect the registry.

## Good / Bad Examples

Good – Ensure success, stream, and stop:

```typescript
const response = await proxyfetch(this.API_BASE_URL + "/messages", {
  ...this.buildAPIRequest("POST"),
  body,
  signal,
});
await this.ensureSuccess(response);
const reader = response.body?.getReader();
if (!reader)
  throw new ExpectedError(response.status, "common_http_error", "No reader");
try {
  /* read SSE, call result(...) and setStop(...) */
} finally {
  reader.releaseLock();
}
```

Bad – Skipping stop mapping and clean-up:

```typescript
// not setting setStop() on completion and not releasing the reader lock
```

Good – Tool schema mapping:

```typescript
// Anthropic
return tools.map((t) => ({
  name: t.id,
  description: t.description,
  input_schema: t.jsonSchema,
}));
// OpenAI
return tools.map((t) => ({
  type: "function",
  name: t.id,
  strict: false,
  parameters: t.jsonSchema,
  description: t.description,
}));
```

Bad – Diverging tool names:

```typescript
// name does not match tool.id – breaks tool execution wiring
name: t.displayName;
```

## Checklist for Provider Changes

Use this checklist when editing or adding provider functionality:

- [ ] Headers and auth are correct in `buildAPIRequest`
- [ ] `ensureSuccess` normalizes provider errors into `ExpectedError`
- [ ] System prompts include datetime and user prompts
- [ ] Session translation matches provider input model
- [ ] Tools schema translation matches provider spec
- [ ] Streaming parses only `data: ` lines and handles partials
- [ ] Start/End lifecycle events are emitted
- [ ] Stop reasons mapped (`log` / `message` / `tool_use`)
- [ ] Reader lock is released in `finally`
- [ ] AbortSignal is wired into network call
- [ ] Config defaults/schemas validated against registry bounds
- [ ] Model registry updated consistently with new capabilities

## Do Not

- Do not use `fetch` directly – always use `proxyfetch`.
- Do not write to `localStorage` or `sessionStorage` from providers.
- Do not modify session structure directly; only mutate via `result(updator)`.
- Do not change tool `name` away from tool `id`.
- Do not bypass `ensureSuccess` checks.
